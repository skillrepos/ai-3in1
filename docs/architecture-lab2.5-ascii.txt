================================================================================
LAB 2.5 ARCHITECTURE: Adding Conversation Memory to Agents (OPTIONAL)
================================================================================

OVERVIEW
--------
Extends Lab 2's agent with conversation memory using a buffer-based approach
for context-aware, multi-turn interactions.


SYSTEM ARCHITECTURE
-------------------

                    ┌──────────────────────────────────────────────────┐
                    │         AGENT WITH MEMORY                        │
                    │                                                  │
                    │  ┌────────────────────────────────────────────┐  │
                    │  │  CONVERSATION MEMORY (Buffer)              │  │
                    │  │                                            │  │
                    │  │  ┌──────────────────────────────────────┐  │  │
                    │  │  │ deque(maxlen=5)                      │  │  │
                    │  │  │                                      │  │  │
                    │  │  │  [Exchange 1] → "Paris: 72°F"        │  │  │
                    │  │  │  [Exchange 2] → "London: 65°F"       │  │  │
                    │  │  │  [Exchange 3] → "Tokyo: 68°F"        │  │  │
                    │  │  │  [Exchange 4] → Empty                │  │  │
                    │  │  │  [Exchange 5] → Empty                │  │  │
                    │  │  │                                      │  │  │
                    │  │  │  Oldest → [1] [2] [3] [ ] [ ] ← Newest  │
                    │  │  └──────────────────────────────────────┘  │  │
                    │  └────────────────────────────────────────────┘  │
                    │                    ▲        │                    │
                    │                    │        │                    │
                    │            Retrieve│        │Store               │
                    │                    │        ▼                    │
                    │  ┌────────────────────────────────────────────┐  │
                    │  │  AGENT LOOP (Enhanced with Context)        │  │
                    │  │                                            │  │
                    │  │  1. Get memory context                     │  │
                    │  │     ↓                                      │  │
                    │  │  2. Build prompt: System + Memory + Query  │  │
                    │  │     ↓                                      │  │
                    │  │  3. LLM processes with context             │  │
                    │  │     ↓                                      │  │
                    │  │  4. Execute tools                          │  │
                    │  │     ↓                                      │  │
                    │  │  5. Generate response                      │  │
                    │  │     ↓                                      │  │
                    │  │  6. Store exchange in memory               │  │
                    │  └────────────────────────────────────────────┘  │
                    └──────────────────────────────────────────────────┘


MEMORY WORKFLOW: FIRST QUERY (NO CONTEXT)
------------------------------------------

User: "What's the weather in Paris?"

    ┌─────────────────────┐
    │ 1. Retrieve Memory  │
    │    Result: Empty    │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 2. Build Prompt     │
    │    System + Query   │  (No memory context)
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 3. LLM Processing   │
    │    (Standard TAO)   │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 4. Response         │
    │    "Paris: 72°F,    │
    │     Sunny"          │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 5. Store in Memory  │
    │    Exchange 1:      │
    │    Q: Paris?        │
    │    A: 72°F Sunny    │
    └─────────────────────┘


MEMORY WORKFLOW: SECOND QUERY (WITH CONTEXT)
---------------------------------------------

User: "What about London?"

    ┌─────────────────────┐
    │ 1. Retrieve Memory  │
    │    Result:          │
    │    "User asked:     │
    │     Paris           │
    │    Agent: 72°F"     │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 2. Build Prompt     │
    │    System +         │
    │    Memory Context + │  ← Includes Paris conversation
    │    Query            │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 3. LLM Processing   │
    │    LLM knows about  │
    │    Paris now        │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 4. Response         │
    │    "London: 65°F,   │
    │     Cloudy"         │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 5. Store in Memory  │
    │    Exchange 2:      │
    │    Q: London?       │
    │    A: 65°F Cloudy   │
    └─────────────────────┘


MEMORY WORKFLOW: FOLLOW-UP QUERY (USES CONTEXT)
------------------------------------------------

User: "Which one is warmer?"

    ┌─────────────────────┐
    │ 1. Retrieve Memory  │
    │    Result:          │
    │    Ex 1: Paris 72°F │
    │    Ex 2: London 65°F│
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 2. Build Prompt     │
    │    System +         │
    │    Memory Context + │  ← Has both conversations
    │    Query            │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 3. LLM Processing   │
    │    LLM can compare  │
    │    using context    │
    └──────────┬──────────┘
               │
               ▼
    ┌─────────────────────┐
    │ 4. Response         │
    │    "Paris is warmer │
    │    at 72°F vs       │
    │    London's 65°F"   │
    └─────────────────────┘


CONVERSATIONMEMORY CLASS STRUCTURE
-----------------------------------

┌──────────────────────────────────────────────────────────────┐
│ class ConversationMemory                                     │
├──────────────────────────────────────────────────────────────┤
│ Attributes:                                                  │
│   • memory: deque(maxlen=max_exchanges)                      │
│   • max_exchanges: int (default: 5)                          │
├──────────────────────────────────────────────────────────────┤
│ Methods:                                                     │
│                                                              │
│   __init__(max_exchanges=5)                                  │
│     └─ Initialize deque with max capacity                   │
│                                                              │
│   add_exchange(user_query, agent_response)                   │
│     └─ Store exchange with timestamp                        │
│        {                                                     │
│          "user": query,                                      │
│          "agent": response,                                  │
│          "timestamp": "HH:MM:SS"                             │
│        }                                                     │
│                                                              │
│   get_context_string() -> str                                │
│     └─ Format memory for LLM prompt:                        │
│        "Previous conversation context:                      │
│         User: [query 1]                                     │
│         Agent: [response 1]                                 │
│         User: [query 2]                                     │
│         Agent: [response 2]"                                │
│                                                              │
│   get_summary() -> str                                       │
│     └─ Return "N/max exchanges stored"                      │
│                                                              │
│   clear()                                                    │
│     └─ Empty the deque                                      │
│                                                              │
│   is_empty() -> bool                                         │
│     └─ Check if memory has exchanges                        │
└──────────────────────────────────────────────────────────────┘


MEMORY BUFFER VISUALIZATION
----------------------------

Initial State (Empty):
┌───┬───┬───┬───┬───┐
│   │   │   │   │   │  maxlen=5
└───┴───┴───┴───┴───┘
  0   1   2   3   4

After Query 1 (Paris):
┌───────┬───┬───┬───┬───┐
│Paris  │   │   │   │   │
│72°F   │   │   │   │   │
└───────┴───┴───┴───┴───┘
  [0]     1   2   3   4

After Query 2 (London):
┌───────┬────────┬───┬───┬───┐
│Paris  │London  │   │   │   │
│72°F   │65°F    │   │   │   │
└───────┴────────┴───┴───┴───┘
  [0]     [1]      2   3   4

After Queries 3-5 (Tokyo, Berlin, Madrid):
┌───────┬────────┬───────┬────────┬────────┐
│Paris  │London  │Tokyo  │Berlin  │Madrid  │
│72°F   │65°F    │68°F   │60°F    │75°F    │
└───────┴────────┴───────┴────────┴────────┘
  [0]     [1]      [2]     [3]      [4]     FULL

After Query 6 (Rome) - Oldest Dropped:
┌────────┬───────┬────────┬────────┬──────┐
│London  │Tokyo  │Berlin  │Madrid  │Rome  │
│65°F    │68°F   │60°F    │75°F    │70°F  │
└────────┴───────┴────────┴────────┴──────┘
  [0]      [1]     [2]      [3]      [4]
  ↑ Paris dropped (oldest)


CONTEXT INJECTION EXAMPLE
--------------------------

Without Memory:
┌──────────────────────────────────────┐
│ Messages to LLM:                     │
│                                      │
│ [1] System: "You are a weather..."  │
│ [2] User: "What about London?"      │
│                                      │
│ LLM doesn't know what "what about"  │
│ refers to.                           │
└──────────────────────────────────────┘

With Memory:
┌──────────────────────────────────────┐
│ Messages to LLM:                     │
│                                      │
│ [1] System: "You are a weather..."  │
│ [2] System: "Previous context:      │
│     User: Weather in Paris?          │
│     Agent: Paris is 72°F, Sunny"    │
│ [3] User: "What about London?"      │
│                                      │
│ LLM understands context and can     │
│ provide relevant comparison.         │
└──────────────────────────────────────┘


REPL WITH MEMORY DISPLAY
-------------------------

============================================================
Memory Status: 0/5 exchanges stored
============================================================

Location (or 'exit'/'clear'): Paris
[Processing...]
Today will be Clear sky with a high of 75.2 °F

============================================================
Memory Status: 1/5 exchanges stored
Context available for next query
============================================================

Location (or 'exit'/'clear'): London
[Using memory: 1/5 exchanges stored]
[Processing...]
Today will be Partly cloudy with a high of 68.0 °F

============================================================
Memory Status: 2/5 exchanges stored
Context available for next query
============================================================

Location (or 'exit'/'clear'): memory

Memory Statistics:
  Collection: conversation_memory
  Total conversations: 2

============================================================

Location (or 'exit'/'clear'): clear
Memory cleared!

============================================================
Memory Status: 0/5 exchanges stored
============================================================


KEY DIFFERENCES FROM LAB 2
---------------------------

Aspect              Lab 2               Lab 2.5
──────              ─────               ───────
Context             None                Last 5 exchanges
Multi-turn          No                  Yes
Memory              Stateless           Buffer (deque)
Follow-ups          Can't handle        Understands
Complexity          Simple              +30 lines of code
State               No state            In-memory state


PERFORMANCE IMPACT
------------------

Metric                  Without Memory    With Memory
──────                  ──────────────    ───────────
Latency per query       3-6s              3-6s (same)
Context size            ~500 tokens       ~500-1000 tokens
Memory usage            Minimal           +few KB per exchange
Token cost per query    Base              +100-200 tokens


KEY LEARNING POINTS
-------------------

1. BUFFER MEMORY PATTERN
   - Sliding window (FIFO)
   - Fixed capacity
   - Auto-cleanup with deque

2. CONTEXT INJECTION
   - Add memory to prompts
   - LLM sees conversation history
   - Enables referential queries

3. STATEFUL AGENTS
   - Maintain conversation state
   - Handle pronouns ("it", "that one")
   - Compare across queries

4. MEMORY MANAGEMENT
   - Display status
   - Clear on command
   - Monitor token usage


LIMITATIONS
-----------

- Buffer size limited (5 exchanges)
- In-memory only (not persistent)
- No semantic search
- Simple FIFO (no importance ranking)
- Grows token usage


NEXT STEPS
----------

Lab 3: MCP protocol for tool separation
Lab 5: Vector-based semantic memory (vs buffer)
Lab 8: Session state memory in web UI

================================================================================
