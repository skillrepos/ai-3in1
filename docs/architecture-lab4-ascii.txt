================================================================================
LAB 4 ARCHITECTURE: Working with Vector Databases
================================================================================

OVERVIEW
--------
Introduction to vector databases (ChromaDB) for semantic search and similarity
matching, enabling RAG (Retrieval-Augmented Generation) capabilities.


SYSTEM ARCHITECTURE
-------------------

INDEXING PHASE                          SEARCH PHASE
──────────────                          ────────────

┌─────────────────┐                    ┌─────────────────┐
│  SOURCE DATA    │                    │  USER QUERY     │
│                 │                    │  "High revenue  │
│ • offices.pdf   │                    │   branch"       │
│ • *.py files    │                    └────────┬────────┘
└────────┬────────┘                             │
         │                                      │
         ▼                                      ▼
┌─────────────────┐                    ┌─────────────────┐
│  TEXT CHUNKER   │                    │ EMBED QUERY     │
│                 │                    │                 │
│ Split into      │                    │ all-MiniLM-L6-v2│
│ 512-char chunks │                    │ 384 dimensions  │
└────────┬────────┘                    └────────┬────────┘
         │                                      │
         │                                      │
         ▼                                      ▼
┌─────────────────┐                    ┌─────────────────┐
│ EMBEDDING MODEL │                    │ VECTOR SEARCH   │
│                 │                    │                 │
│ all-MiniLM-L6-v2│                    │ Cosine          │
│ Text → Vector   │                    │ Similarity      │
│ [0.12,-0.45,...]│                    │                 │
└────────┬────────┘                    │ ┌─────────────┐ │
         │                             │ │Find closest │ │
         │                             │ │vectors      │ │
         ▼                             │ └─────────────┘ │
┌─────────────────┐                    └────────┬────────┘
│   CHROMADB      │◄───────────────────────────┘
│  Vector Store   │
│                 │
│ ┌─────────────┐ │
│ │Collection:  │ │                    ┌─────────────────┐
│ │ "codebase"  │ │                    │  TOP-K RESULTS  │
│ │             │ │                    │                 │
│ │50 chunks    │ │──────────────────▶ │ 1. NY: $85M     │
│ │50 vectors   │ │                    │    (score: 0.92)│
│ │384-dim each │ │                    │ 2. SF: $78M     │
│ └─────────────┘ │                    │    (score: 0.88)│
└─────────────────┘                    │ 3. ...          │
   Persistent Storage                  └─────────────────┘
   ./chroma_db/


VECTOR EMBEDDING PROCESS
-------------------------

Document Text                Vector Representation
─────────────                ─────────────────────

"New York Office             [0.145, -0.423, 0.887, ..., 0.234]
 120 employees                     ↑
 $85.5M revenue"              384 dimensions
                              
                              Each number represents
                              semantic features:
                              - Topic relevance
                              - Entity types
                              - Context meaning


┌────────────────────────────────────────────────────────────┐
│ EMBEDDING MODEL: all-MiniLM-L6-v2                          │
├────────────────────────────────────────────────────────────┤
│ Input:  Text string (any length)                           │
│ Output: 384-dimensional vector                             │
│                                                            │
│ Properties:                                                │
│ • Captures semantic meaning                                │
│ • Similar texts → similar vectors                          │
│ • Distance = relevance                                     │
│                                                            │
│ Example:                                                   │
│   "high revenue" → [0.16, -0.44, 0.91, ...]                │
│   "top earning"  → [0.15, -0.42, 0.89, ...]  (similar!)    │
│   "many staff"   → [0.82, 0.31, -0.22, ...]  (different)   │
└────────────────────────────────────────────────────────────┘


INDEXING WORKFLOW
-----------------

Step 1: Load Document
┌────────────────────────────────────┐
│ offices.pdf                        │
│                                    │
│ New York Office                    │
│ 123 Main St, New York, NY          │
│ 120 employees, $85.5M revenue      │
│ Opened: 2005                       │
│ Departments: Sales, Marketing...   │
│                                    │
│ San Francisco Office               │
│ 456 Tech Blvd, San Francisco, CA   │
│ 95 employees, $78.2M revenue...    │
└────────────────────────────────────┘

Step 2: Chunk Text (512 chars)
┌────────────────────────────────────┐
│ Chunk 1:                           │
│ "New York Office 123 Main St,      │
│  New York, NY 120 employees,       │
│  $85.5M revenue Opened: 2005..."   │
└────────────────────────────────────┘
┌────────────────────────────────────┐
│ Chunk 2:                           │
│ "San Francisco Office 456 Tech     │
│  Blvd, San Francisco, CA 95        │
│  employees, $78.2M revenue..."     │
└────────────────────────────────────┘

Step 3: Generate Embeddings
Chunk 1 → Model → [0.12, -0.45, 0.87, ..., 0.23]
Chunk 2 → Model → [0.14, -0.43, 0.85, ..., 0.25]

Step 4: Store in ChromaDB
┌────────────────────────────────────┐
│ Collection: "codebase"             │
│                                    │
│ Document 1:                        │
│   ID: chunk_001                    │
│   Text: "New York Office..."       │
│   Vector: [0.12, -0.45, ...]       │
│                                    │
│ Document 2:                        │
│   ID: chunk_002                    │
│   Text: "San Francisco Office..."  │
│   Vector: [0.14, -0.43, ...]       │
└────────────────────────────────────┘


SEARCH WORKFLOW
---------------

Step 1: User Query
Input: "High revenue branch"

Step 2: Embed Query
Query → Model → [0.16, -0.44, 0.91, ..., 0.26]

Step 3: Compute Similarity (Cosine)
                 
Vector Space (simplified to 2D):
                    ▲
                    │
         Query ●    │    ● Chunk 2 (SF)
                    │   /
                    │  /
                    │ /
    ────────────────┼──────────▶
                    │╲
                    │ ╲
                    │  ╲
                    │   ● Chunk 1 (NY) ← Closest!
                    │

Cosine Similarity Scores:
  Chunk 1 (NY):  0.92  ← Most similar
  Chunk 2 (SF):  0.88
  Chunk 3 (CHI): 0.75
  ...

Step 4: Return Top-K (K=5)
┌────────────────────────────────────┐
│ Results (sorted by similarity):    │
│                                    │
│ 1. [0.92] New York Office          │
│           120 employees, $85.5M... │
│                                    │
│ 2. [0.88] San Francisco Office     │
│           95 employees, $78.2M...  │
│                                    │
│ 3. [0.75] Chicago Office           │
│           85 employees, $52.3M...  │
└────────────────────────────────────┘


COSINE SIMILARITY CALCULATION
------------------------------

Formula:
                    A · B
    similarity = ─────────────
                 ||A|| × ||B||

Where:
  A = Query vector
  B = Document vector
  · = Dot product
  ||·|| = Vector magnitude

Result Range: -1 to 1
  • 1.0  = Identical
  • 0.5  = Somewhat similar
  • 0.0  = Orthogonal (unrelated)
  • -1.0 = Opposite

Example:
Query:    [0.16, -0.44, 0.91]
Document: [0.15, -0.42, 0.89]

Dot product: (0.16×0.15) + (-0.44×-0.42) + (0.91×0.89) = 1.02
Magnitude Q: √(0.16² + 0.44² + 0.91²) = 1.02
Magnitude D: √(0.15² + 0.42² + 0.89²) = 1.00

Similarity: 1.02 / (1.02 × 1.00) = 1.00  (very similar!)


CHROMADB STRUCTURE
------------------

File System:
./chroma_db/
  ├── chroma.sqlite3         ← Metadata database
  ├── index/                 ← HNSW index files
  │   ├── id_to_uuid.pkl
  │   └── index.bin
  └── collections/
      └── codebase/
          ├── data.parquet   ← Document texts
          └── vectors.npy    ← Embedding vectors

Collection Schema:
┌─────────────────────────────────────────────────────┐
│ Collection: "codebase"                              │
├─────────────────────────────────────────────────────┤
│ Field         Type              Example             │
├─────────────────────────────────────────────────────┤
│ id            string            "chunk_001"         │
│ document      string            "New York Office..."│
│ embedding     float[384]        [0.12, -0.45, ...]  │
│ metadata      dict (optional)   {"source": "pdf"}   │
└─────────────────────────────────────────────────────┘


INDEXING TOOLS
--------------

Tool 1: index_code.py
┌────────────────────────────────────────────────────┐
│ Purpose: Index Python source files                 │
│                                                    │
│ Process:                                           │
│ 1. Find all *.py files                             │
│ 2. Read file contents                              │
│ 3. Chunk into 512-char pieces                      │
│ 4. Generate embeddings                             │
│ 5. Store in ChromaDB                               │
│                                                    │
│ Output: ~100 chunks from codebase                  │
└────────────────────────────────────────────────────┘

Tool 2: index_pdf.py
┌────────────────────────────────────────────────────┐
│ Purpose: Index PDF documents                       │
│                                                    │
│ Process:                                           │
│ 1. Extract text from PDF (pypdf)                   │
│ 2. Clean and normalize text                        │
│ 3. Chunk into 512-char pieces                      │
│ 4. Generate embeddings                             │
│ 5. Store in ChromaDB                               │
│                                                    │
│ Output: ~50 chunks from offices.pdf                │
└────────────────────────────────────────────────────┘

Tool 3: search.py
┌────────────────────────────────────────────────────┐
│ Purpose: Interactive semantic search               │
│                                                    │
│ Process:                                           │
│ 1. Accept user query                               │
│ 2. Embed query                                     │
│ 3. Search ChromaDB                                 │
│ 4. Display top-K results with scores               │
│                                                    │
│ Example Output:                                    │
│   Query: "high revenue"                            │
│   [0.92] New York Office, $85.5M...                │
│   [0.88] San Francisco Office, $78.2M...           │
└────────────────────────────────────────────────────┘


KEYWORD VS SEMANTIC SEARCH
---------------------------

Query: "high revenue branch"

KEYWORD SEARCH:
┌────────────────────────────────────┐
│ Match Algorithm: Exact word match  │
│                                    │
│ Finds:                             │
│ • Contains "high" ✓                │
│ • Contains "revenue" ✓             │
│ • Contains "branch" ✗              │
│                                    │
│ Misses:                            │
│ ✗ "top earning office"             │
│ ✗ "most profitable location"       │
│ ✗ "$85M" (semantic match)          │
└────────────────────────────────────┘

SEMANTIC SEARCH:
┌────────────────────────────────────┐
│ Match Algorithm: Vector similarity │
│                                    │
│ Finds:                             │
│ ✓ "New York, $85.5M revenue"       │
│ ✓ "top earning office"             │
│ ✓ "most profitable location"       │
│ ✓ "highest sales branch"           │
│                                    │
│ Understanding:                     │
│ • "high" ≈ "top" ≈ "most"          │
│ • "revenue" ≈ "earning" ≈ "sales"  │
│ • "branch" ≈ "office" ≈ "location" │
└────────────────────────────────────┘


PERFORMANCE CHARACTERISTICS
----------------------------

Operation           Metric              Value
─────────           ──────              ─────
Embedding Speed     Sentences/sec       ~1000 (CPU)
                                       ~5000 (GPU)

Index Size          10 offices (50 chunks)
  - Text data       ~20 KB
  - Vectors         ~75 KB (50 × 384 × 4 bytes)
  - Index overhead  ~50 KB
  - Total           ~145 KB

Search Latency      
  - Embed query     10-50 ms
  - Vector search   5-20 ms (1K docs)
                    50-100 ms (100K docs)
  - Total           15-150 ms

Accuracy            Top-1 precision     ~85%
                    Top-5 precision     ~95%


VECTOR SPACE VISUALIZATION (2D Projection)
-------------------------------------------

Actual vectors are 384-dimensional, but conceptually:

            Revenue / Finance
                   ▲
                   │
        High Rev ● │
                   │
    NY Office ●    │    ● Top Earning
                   │
    ───────────────┼──────────────────▶ Geography
                   │
         ● Paris   │    ● London
                   │
                   │ ● Most Staff
                   │
            Employee Count

Points close together = Semantically similar
Distance = Inverse relevance


CODE EXAMPLE: USING CHROMADB
-----------------------------

from sentence_transformers import SentenceTransformer
import chromadb

# Initialize
model = SentenceTransformer("all-MiniLM-L6-v2")
client = chromadb.PersistentClient(path="./chroma_db")
collection = client.get_or_create_collection("codebase")

# Index documents
texts = ["New York Office, $85M...", "SF Office, $78M..."]
embeddings = model.encode(texts)
collection.add(
    documents=texts,
    embeddings=embeddings.tolist(),
    ids=["chunk_1", "chunk_2"]
)

# Search
query = "high revenue branch"
query_embedding = model.encode(query)
results = collection.query(
    query_embeddings=[query_embedding.tolist()],
    n_results=5
)

print(results["documents"][0])  # Top 5 results


KEY LEARNING POINTS
-------------------

1. VECTOR EMBEDDINGS
   - Text → Numeric representation
   - Preserves semantic meaning
   - Enables similarity comparison

2. SEMANTIC SEARCH
   - Finds meaning, not keywords
   - Handles synonyms naturally
   - Context-aware matching

3. CHROMADB
   - Persistent vector storage
   - Efficient similarity search (HNSW algorithm)
   - Simple Python API

4. CHUNKING STRATEGY
   - Balance: too small (loses context), too large (too general)
   - 512 characters = sweet spot for this use case
   - Overlap optional for better coverage

5. RAG FOUNDATION
   - Retrieval step in RAG pipeline
   - Provides relevant context to LLM
   - Grounds responses in documents


USE CASES
---------

✓ Document search (semantic, not keyword)
✓ Code search (find similar patterns)
✓ Question answering (retrieve relevant context)
✓ Recommendation systems (find similar items)
✓ Duplicate detection (find near-duplicates)
✓ RAG pipelines (next lab!)


LIMITATIONS
-----------

- Embedding quality depends on model
- No understanding of recency (older = newer in vector space)
- Storage grows with document count
- Rebuild index when model changes
- No reasoning (just similarity)


NEXT STEPS
----------

Lab 5: Combine vector search (RAG) with agent (Lab 3)
       to create knowledge-grounded responses

================================================================================
